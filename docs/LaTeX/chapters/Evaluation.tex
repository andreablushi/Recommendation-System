\section{Evaluation}
In this section, we present the evaluation results, for both $\textit{prefix\_length}=5$ and $\textit{prefix\_length}=10$, of the decision tree classifier and the recommendation system built on top of it.

\subsection{Hyperparameters}
Tables~\ref{tab:hyperparameters_5} and~\ref{tab:hyperparameters_10} show the optimized hyperparameters obtained through \textit{Hyperopt} for both prefix lengths. 
Both configurations use entropy as the splitting criterion, which measures information gain and tends to create more balanced trees. 
The max depth parameters (17 and 15 respectively) prevent overfitting while allowing sufficient model complexity to capture the underlying patterns. 
Note that the model for $\textit{prefix\_length}=10$ uses only 1 max feature, suggesting that at longer prefix lengths, individual activities become more discriminative for prediction.

\begin{table}[ht]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Hyperparameter} & \textbf{Value} \\
            \hline
            Criterion & Entropy \\
            Max Depth & 17 \\
            Max Features & 3 \\
            \hline
        \end{tabular}
        \caption{Optimized hyperparameters for the decision tree classifier for $\textit{prefix\_length}=5$.}
        \label{tab:hyperparameters_5}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Hyperparameter} & \textbf{Value} \\
            \hline
            Criterion & Entropy \\
            Max Depth & 15 \\
            Max Features & 1 \\
            \hline
        \end{tabular}
        \caption{Optimized hyperparameters for the decision tree classifier for $\textit{prefix\_length}=10$.}
        \label{tab:hyperparameters_10}
    \end{minipage}
\end{table}


\subsection{Decision Tree Structure}
Figures~\ref{fig:decision_tree_5} and~\ref{fig:decision_tree_10} illustrate the structure of the trained decision trees.
The color-coded leaf nodes (blue for positive outcomes, orange for negative outcomes) clearly show the distribution of predictions across different decision paths. 
Both trees maintain interpretability despite their depth, as the controlled max depth parameters prevent excessive branching.
The tree structures provide valuable insights into which activities and activity combinations are most discriminative for predicting case outcomes, making the model transparent.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../media/decision_tree_5.png}
    \caption{Visualization of the trained decision tree classifier for $\textit{prefix\_length}=5$. Each node represents a decision based on the presence or absence of specific activities, leading to recommendations at the leaf nodes.}
    \label{fig:decision_tree_5}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../media/decision_tree_10.png}
    \caption{Visualization of the trained decision tree classifier for $\textit{prefix\_length}=10$. }
    \label{fig:decision_tree_10}
\end{figure}

\subsubsection{Evaluation Metrics}

The classification results in Tables~\ref{tab:evaluation_metrics_5} and~\ref{tab:evaluation_metrics_10} demonstrate the predictive performance of our decision tree models. 
For $\textit{prefix\_length}=5$, the model achieves balanced results around the $70\%$ for all considered metrics. 
This indicates reasonable performance given that the model has access to only the first 5 activities of each case.

The performance improves significantly at $\textit{prefix\_length}=10$.
This improvement suggests that longer prefixes provide substantially more discriminative information for predicting case outcomes. 

The confusion matrices in Figures~\ref{fig:confusion_matrix_5} and~\ref{fig:confusion_matrix_10} provide further insight into the distribution of predictions and misclassifications.

\begin{figure}[H]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../media/confusion_matrix_5.png}
        \caption{Confusion matrix of predictions in the test set ($\textit{prefix\_length}=5$).}
        \label{fig:confusion_matrix_5}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../media/confusion_matrix_10.png}
        \caption{Confusion matrix of predictions in the test set ($\textit{prefix\_length}=10$).}
        \label{fig:confusion_matrix_10}
    \end{minipage}
\end{figure}

\begin{table}[H]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Metric} & \textbf{Value} \\
            \hline
            Accuracy & 72.09\% \\
            Precision & 73.82\% \\
            Recall & 72.09\% \\
            F1-Score & 72.81\% \\
            \hline
        \end{tabular}
        \caption{Evaluation metrics for the decision tree classifier on the test set for $\textit{prefix\_length}=5$.}
        \label{tab:evaluation_metrics_5}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Metric} & \textbf{Value} \\
            \hline
            Accuracy & 79.07\% \\
            Precision & 78.49\% \\
            Recall & 79.07\% \\
            F1-Score & 78.73\% \\
            \hline
        \end{tabular}
        \caption{Evaluation metrics for the decision tree classifier on the test set for $\textit{prefix\_length}=10$.}
        \label{tab:evaluation_metrics_10}
    \end{minipage}
\end{table}

\subsection{Recommendation Analysis}

\paragraph{Recommendation Generation}
For the sake of simplicity in explaining the recommendation extraction process, we chose to consider the tree in Figure~\ref{fig:decision_tree_recommendation} that, while not optimal, has a smaller depth.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../media/decision_tree_small.png}
    \caption{Simplified decision tree used to illustrate the recommendation extraction process.
    Given a node, the left child branch is taken if the condition is true (activity is absent in the trace), while the right child branch is taken if the condition is false (activity is present in the trace).}
    \label{fig:decision_tree_recommendation}
\end{figure}
Applying the extraction of positive paths (Algorithm~\ref{alg:get_positive_paths}) to this tree, we obtain the following positive paths with their confidence scores:
\begin{itemize}
    \item Path 1: \textit{Turning Q.C.} = F $\wedge$ \textit{Grinding Rework - Machine 27} = F $\wedge$ \textit{Turning - Machine 9} = F $\wedge$ \textit{Turning \& Milling Q.C.} = F with confidence $0.77$;
    \item Path 2: \textit{Turning Q.C.} = F $\wedge$ \textit{Grinding Rework - Machine 27} = F $\wedge$ \textit{Turning - Machine 9} = T with confidence $0.80$;
    \item Path 3: \textit{Turning Q.C.} = T $\wedge$ \textit{Turning \& Milling - Machine 10} = F $\wedge$ \textit{Final Inspection Q.C.} = F $\wedge$ \textit{Packing} = T with confidence $1.0$;
    \item Path 4: \textit{Turning Q.C.} = T $\wedge$ \textit{Turning \& Milling - Machine 10} = T with confidence $1.0$;
\end{itemize}
Now, suppose a prefix trace that has the following activities: \{\textit{Final Inspection Q.C.}: True, \textit{Packing}: True, \textit{Grinding Rework - Machine 27}: True\}, represented by the orange path in Figure~\ref{fig:decision_tree_recommendation} is predicted as false.
To find the recommendations for this trace, we first filter the positive paths to find the compliant ones.
\begin{itemize}
    \item Path 1 and Path 2 are not compliant because they require \textit{Grinding Rework - Machine 27} = F, which is violated by the trace;
    \item Path 3 is compliant because none of its conditions are violated by the trace;
    \item Path 4 is also not compliant because it requires \textit{Final Inspection Q.C.} = F, which is violated by the trace.
\end{itemize}
Given this, we can derive the recommendations for the given prefix trace as the activities that need to be added to follow Path 3.
Since both \textit{Turning Q.C.} and \textit{Turning \& Milling - Machine 10} need to be true to follow Path 3, the recommended activities will be them.
This is illustrated in Figure~\ref{fig:recommendation_tree}, with the green dotted nodes.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../media/recommendation_tree.png}
    \caption{The blue squared nodes represent the activities present in the given prefix trace. The green highlighted node represent the recommended activities}
    \label{fig:recommendation_tree}
\end{figure}

\paragraph{Recommendations Quality}
Tables~\ref{tab:evaluation_metrics_rec_5} and~\ref{tab:evaluation_metrics_rec_10} present the evaluation of our recommendation system.
This values have to be considered as an approximation, since the ground truth is based on actual traces rather than hypothetical scenarios where recommendations were followed.
At $\textit{prefix\_length}=5$, the recommendation system achieves a balanced accuracy like the classifier, with all metrics around 78\%. 
This indicates that even with limited information from shorter prefixes, the system can provide reasonably accurate recommendations.

The recommendation system shows marked improvement at $\textit{prefix\_length}=10$.
Most notably, the precision increases dramatically to 93.75\%, indicating that when the system makes recommendations, they are highly likely to be correct. 
This strong performance, particularly the high precision at $\textit{prefix\_length}=10$, suggests that the recommendation system can be reliably deployed to guide ongoing cases toward positive outcomes. 

\begin{table}[H]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Metric} & \textbf{Value} \\
            \hline
            Accuracy & 78.12\% \\
            Precision & 78.12\% \\
            Recall & 78.12\% \\
            F1-Score & 67.44\% \\
            \hline
        \end{tabular}
        \caption{Evaluation metrics for the recommendation system on the test set for $\textit{prefix\_length}=5$.}
        \label{tab:evaluation_metrics_rec_5}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Metric} & \textbf{Value} \\
            \hline
            Accuracy & 78.95\% \\
            Precision & 93.75\% \\
            Recall & 85.71\% \\
            F1-Score & 76.74\% \\
            \hline
        \end{tabular}
        \caption{Evaluation metrics for the recommendation system on the test set for $\textit{prefix\_length}=10$.}
        \label{tab:evaluation_metrics_rec_10}
    \end{minipage}
\end{table}