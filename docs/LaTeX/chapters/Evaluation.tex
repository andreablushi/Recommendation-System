\section{Evaluation}
In this section, we present the evaluation results for both $\textit{prefix\_length}=5$ and $\textit{prefix\_length}=11$ of the decision tree classifier and the recommendation system built on top of it.

\subsection{Hyperparameters}
Tables~\ref{tab:hyperparameters_5} and~\ref{tab:hyperparameters_11} show the optimized hyperparameters obtained through \textit{Hyperopt} for both prefix lengths. 
\\\\
For $\textit{prefix\_length}=5$, the optimizer selects a shallow tree with a maximum depth of $3$ and a small number of features considered at each split.
This choice limits overfitting in a setting where only partial information about the trace is available, while still allowing the model to exploit the most informative activities.
The use of the entropy criterion leads to more balanced and interpretable decision paths.
\\\\
For $\textit{prefix\_length}=11$, the optimal configuration still constrains the maximum depth to $3$, confirming that deeper trees do not provide additional benefits even when more information is available.
However, the maximum number of features increases, indicating that longer prefixes allow the model to effectively leverage a richer set of activities.
In this case, the Gini criterion is selected, suggesting that it better captures class separation when more contextual information is present.

\begin{table}[ht]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Hyperparameter} & \textbf{Value} \\
            \hline
            Criterion & Entropy \\
            Max Depth & 3 \\
            Max Features & 2 \\
            \hline
        \end{tabular}
        \caption{Optimized hyperparameters for the decision tree classifier for $\textit{prefix\_length}=5$.}
        \label{tab:hyperparameters_5}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Hyperparameter} & \textbf{Value} \\
            \hline
            Criterion & Gini \\
            Max Depth & 3 \\
            Max Features & 3 \\
            \hline
        \end{tabular}
        \caption{Optimized hyperparameters for the decision tree classifier for $\textit{prefix\_length}=11$.}
        \label{tab:hyperparameters_11}
    \end{minipage}
\end{table}


\subsection{Decision Tree Structure}
Figures~\ref{fig:decision_tree_5} and~\ref{fig:decision_tree_11} illustrate the structure of the trained decision trees.
The color-coded leaf nodes (blue for positive outcomes, orange for negative outcomes) clearly show the distribution of predictions across different decision paths. 
Both trees maintain interpretability thanks to their depth, as the controlled \textit{max\_depth} and \textit{max\_features} parameters prevent excessive branching.
The tree structures provide valuable insights into which activities are most discriminative for predicting case outcomes, making the model transparent.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../media/decision_tree_5.png}
    \caption{Visualization of the trained decision tree classifier for $\textit{prefix\_length}=5$. Each node represents a decision based on the presence or absence of specific activities, leading to recommendations at the leaf nodes.}
    \label{fig:decision_tree_5}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../media/decision_tree_11.png}
    \caption{Visualization of the trained decision tree classifier for $\textit{prefix\_length}=11$.}
    \label{fig:decision_tree_11}
\end{figure}

\subsubsection{Evaluation Metrics}

The classification results in Tables~\ref{tab:evaluation_metrics_5} and~\ref{tab:evaluation_metrics_11} demonstrate the predictive performance of our decision tree models. 
\\\\
For $\textit{prefix\_length}=5$, these results indicate reasonably balanced performance when only a limited portion of each trace is available.
In this setting, the model is already able to capture meaningful patterns, but the reduced amount of information limits its power.
\\\\
The performance further improves for $\textit{prefix\_length}=11$, where the results suggest that longer prefixes provide more informative context, enabling the model to make more confident positive predictions.
Overall, the results confirm that increasing the \textit{prefix\_length} has a positive impact on outcome prediction, as more activities contribute to defining the case trajectory.
\\\\
The confusion matrices in Figures~\ref{fig:confusion_matrix_5} and~\ref{fig:confusion_matrix_11} provide further insight into the distribution of predictions and misclassifications.

\begin{figure}[H]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../media/confusion_matrix_5.png}
        \caption{Confusion matrix of predictions in the test set ($\textit{prefix\_length}=5$).}
        \label{fig:confusion_matrix_5}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../media/confusion_matrix_11.png}
        \caption{Confusion matrix of predictions in the test set ($\textit{prefix\_length}=11$).}
        \label{fig:confusion_matrix_11}
    \end{minipage}
\end{figure}

\begin{table}[H]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Metric} & \textbf{Value} \\
            \hline
            Accuracy & 69.77\% \\
            Precision & 64.84\% \\
            Recall & 69.77\% \\
            F1-Score & 66.42\% \\
            \hline
        \end{tabular}
        \caption{Evaluation metrics for the decision tree classifier on the test set for $\textit{prefix\_length}=5$.}
        \label{tab:evaluation_metrics_5}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Metric} & \textbf{Value} \\
            \hline
            Accuracy & 81.40\% \\
            Precision & 84.45\% \\
            Recall & 81.40\% \\
            F1-Score & 82.21\% \\
            \hline
        \end{tabular}
        \caption{Evaluation metrics for the decision tree classifier on the test set for $\textit{prefix\_length}=11$.}
        \label{tab:evaluation_metrics_11}
    \end{minipage}
\end{table}

\subsection{Recommendation Analysis}

\paragraph{Recommendation Generation}
For the sake of simplicity in explaining the recommendation extraction process, we chose to consider the tree in Figure~\ref{fig:decision_tree_recommendation}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../media/decision_tree_small.png}
    \caption{Simplified decision tree used to illustrate the recommendation extraction process.
    Given a node, the left child branch is taken if the condition is true (activity is absent in the trace), while the right child branch is taken if the condition is false (activity is present in the trace).}
    \label{fig:decision_tree_recommendation}
\end{figure}
Applying the extraction of positive paths (Algorithm~\ref{alg:get_positive_paths}) to this tree, we obtain the following positive paths with their confidence scores:
\begin{itemize}
    \item Path 1: \textit{Turning Q.C.} = F $\wedge$ \textit{Grinding Rework - Machine 27} = F $\wedge$ \textit{Turning - Machine 9} = F $\wedge$ \textit{Turning \& Milling Q.C.} = F with confidence $0.77$;
    \item Path 2: \textit{Turning Q.C.} = F $\wedge$ \textit{Grinding Rework - Machine 27} = F $\wedge$ \textit{Turning - Machine 9} = T with confidence $0.80$;
    \item Path 3: \textit{Turning Q.C.} = T $\wedge$ \textit{Turning \& Milling - Machine 10} = F $\wedge$ \textit{Final Inspection Q.C.} = F $\wedge$ \textit{Packing} = T with confidence $1.0$;
    \item Path 4: \textit{Turning Q.C.} = T $\wedge$ \textit{Turning \& Milling - Machine 10} = T with confidence $1.0$;
\end{itemize}
Now, suppose a prefix trace that has the following activities: \{\textit{Final Inspection Q.C.}: True, \textit{Packing}: True, \textit{Grinding Rework - Machine 27}: True\}, represented by the orange path in Figure~\ref{fig:decision_tree_recommendation}, is predicted as false.
To find the recommendations for this trace, we first filter the positive paths to find the compliant ones.
\begin{itemize}
    \item Path 1 and Path 2 are not compliant because they require \textit{Grinding Rework - Machine 27} = F, which is violated by the trace;
    \item Path 3 is compliant because none of its conditions are violated by the trace;
    \item Path 4 is also not compliant because it requires \textit{Final Inspection Q.C.} = F, which is violated by the trace.
\end{itemize}
Given this, we can derive the recommendations for the given prefix trace as the activities that need to be added to follow Path 3.
Since both \textit{Turning Q.C.} and \textit{Turning \& Milling - Machine 10} need to be true to follow Path 3, the recommended activities will be those.
This is illustrated in Figure~\ref{fig:recommendation_tree}, with the green dotted nodes.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../media/recommendation_tree.png}
    \caption{The blue squared nodes represent the activities present in the given prefix trace. The green highlighted nodes represent the recommended activities.}
    \label{fig:recommendation_tree}
\end{figure}

\paragraph{Recommendations Quality}
Tables~\ref{tab:evaluation_metrics_rec_5} and~\ref{tab:evaluation_metrics_rec_11} present the evaluation of our recommendation system.
These values have to be considered as an approximation, since the ground truth is based on actual traces rather than hypothetical scenarios where recommendations were followed.
\\\\
Overall, the results indicate that the limited size of the test dataset influences the number of recommendations and, consequently, their statistics.
\\\\
For $\textit{prefix\_length}=5$, we can see that we achieve $0\%$ across all metrics, and the few recommendations generated were considered not followed.
This outcome suggests that with very short prefixes, the system struggles to provide effective recommendations, likely due to insufficient context about the trace.
They then consistently failed to align with the actual trace outcomes.
At this early stage of process execution, the activities observed may not yet be discriminative enough to distinguish between successful and unsuccessful process paths, resulting in recommendations that, while structurally valid according to the decision tree, do not reflect the actual dynamics of successful traces.
\\\\
At $\textit{prefix\_length}=11$, the recommendation system demonstrates substantial improvement across all metrics compared to shorter prefix lengths.
The improved performance at this prefix length confirms that the recommendation system requires substantial contextual information to reliably identify patterns that distinguish successful from unsuccessful process executions and translate them into actionable recommendations.
The higher number of recommendations followed indicates that the system is better able to suggest changes that align with actual successful outcomes in the traces.

\begin{table}[H]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Metric} & \textbf{Value} \\
            \hline
            Accuracy & 0.00\% \\
            Precision & 0.00\% \\
            Recall & 0.00\% \\
            F1-Score & 0.00\% \\
            \hline
        \end{tabular}
        \caption{Evaluation metrics for the recommendation system on the test set for $\textit{prefix\_length}=5$.}
        \label{tab:evaluation_metrics_rec_5}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \begin{tabular}{l c}
            \hline
            \textbf{Metric} & \textbf{Value} \\
            \hline
            Accuracy & 46.67\% \\
            Precision & 60.00\% \\
            Recall & 33.33\% \\
            F1-Score & 42.86\% \\
            \hline
        \end{tabular}
        \caption{Evaluation metrics for the recommendation system on the test set for $\textit{prefix\_length}=11$.}
        \label{tab:evaluation_metrics_rec_11}
    \end{minipage}
\end{table}

For a more detailed understanding of the system's performance, we present the confusion matrices in Figures~\ref{fig:rec_confusion_matrix_5} and~\ref{fig:rec_confusion_matrix_11}.
\begin{figure}[H]
    \centering
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../media/recommendation_confusion_matrix_5.png}
        \caption{Confusion matrix of recommendations ($\textit{prefix\_length}=5$).}
        \label{fig:rec_confusion_matrix_5}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../media/recommendation_confusion_matrix_11.png}
        \caption{Confusion matrix of recommendations ($\textit{prefix\_length}=11$).}
        \label{fig:rec_confusion_matrix_11}
    \end{minipage}
\end{figure}

\subsection{Performance by Prefix Length}
As shown in Figure~\ref{fig:prefix_length_f1_statistics}, the F1-score for the decision tree classifier remains relatively stable across different prefix lengths, while the recommendation system shows a more pronounced improvement as the prefix length increases.
This trend reveals a fundamental difference between the two components: while the classifier can maintain consistent predictive performance regardless of prefix length, the recommendation system requires a minimum threshold of contextual information before it can generate meaningful recommendations.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{../media/prefix_length_f1_statistics.png}
    \caption{The box plots illustrate the distribution of F1-scores across different prefix lengths for both the decision tree classifier and the recommendation system.}
    \label{fig:prefix_length_f1_statistics}
\end{figure}