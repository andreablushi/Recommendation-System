\section{Implementation}
A recommendation system based on a decision tree classifier was implemented to analyze production event logs.
The implementation was developed in Python, leveraging the \textit{PM4Py} library for process mining tasks and the \textit{scikit-learn} for machine learning functionality.
The overall execution workflow is encapsulated in the \textit{notebook.ipynb} file, which orchestrates the execution of all supporting utility functions.

\subsection{Encoding the Event Log}
The event log, provided in \textit{XES} format, was imported using the \textit{PM4Py} library and converted
into a \textit{PM4Py} event log object suitable for subsequent processing.
A pruned version of the event log was then constructed by considering only trace prefixes.
Specifically, each trace was truncated to a fixed number of events defined by the parameter \textit{prefix\_length}.
Since ongoing traces in real-world scenarios are inherently incomplete, the classifier was trained exclusively on such prefixes.
\\\\
Subsequently, the set of unique activity names was extracted from the complete event log and used to define the feature space.
In addition to the activity-based features, each encoded trace included a trace identifier,
the prefix length, and a ground truth label indicating whether the trace outcome was positive or negative.
\\\\
To enable training with a decision tree classifier, the pruned traces were encoded using a \textit{Boolean encoding} representation.
For each unique activity, a binary feature was created indicating whether the activity occurred at least once within the trace prefix.
This encoding scheme results in a fixed-dimensional feature space and avoids the need to pad traces to a uniform length.
The final outcome of this step is a tabular \textit{DataFrame} in which each row corresponds to a trace prefix
and each feature column represents the presence or absence of a specific activity.

\subsection{Training the Decision Tree Classifier}
Following the encoding of the pruned event log, a decision tree classifier was trained using the \textit{scikit-learn} library.  
The encoded dataset was partitioned into a feature matrix $\boldsymbol{X}$, obtained by excluding 
the trace identifier and label columns, and a label vector $\boldsymbol{y}$ containing the ground truth outcomes.
The original \textit{XES} file provided a predefined split between training and test sets, which was preserved during this process.
\\\\
After training the classifier, the learned decision rules were examined by visualizing the resulting decision tree using the visualization utilities provided by \textit{scikit-learn}.

\subsection{Optimizing the Classifier Hyperparameters}
To improve classification performance, hyperparameter optimization was conducted using the \textit{Hyperopt} library.
This tool systematically explores a predefined search space, iteratively testing combinations of critical hyperparameters—such as \textit{max\_depth}, \textit{max\_features}, and the split criterion (e.g., \textit{Gini} or \textit{entropy})—to identify the optimal configuration.
For each configuration, the model was trained and evaluated using the $F_1$-score as the primary performance metric.
The hyperparameter configuration yielding the highest $F_1$-score was selected as the final model.
In addition, the search space for \textit{max\_depth} was restricted to comparatively small values in order to limit model complexity and reduce the risk of overfitting on the training set.

To ensure reproducibility, a fixed random seed was set for all stochastic processes involved in the optimization and training phases.

\subsection{Generating Predictions}
The optimized classifier was subsequently applied on the test set to generate predictions. 
The predicted labels were obtained by applying the model to the feature set derived from the encoded test log. 
Similar to the training phase, the features $(\boldsymbol{X}_{test})$ were constructed by removing the trace identifier and ground truth label columns. 
The classifier's performance was subsequently evaluated using standard scikit-learn metrics, including \textit{Accuracy}, \textit{Precision}, \textit{Recall}, and the \textit{F1-score}.

\subsection{Extracting Recommendations}
Due to the inherent interpretability of decision tree models, the trained classifier can be used to derive proactive recommendations for traces predicted to result in a negative outcome.
The recommendation generation procedure consists of three main steps:
\begin{enumerate}
    \item \textbf{Extracting Positive Paths}: identifying all distinct decision paths leading to leaf nodes associated with a positive outcome.
    \item \textbf{Filtering Compliant Paths}: selecting, for a given negatively predicted trace prefix, those positive paths whose conditions are not violated by the activities already observed.
    \item \textbf{Generating Recommendations}: choosing the compliant positive path with the highest confidence score and determining the activities required to complete that path.
\end{enumerate}
It should be noted that the implemented function signature differs from the originally proposed one.
In particular, the \textit{class\_values} parameter was removed to simplify the implementation, as the experimental setting is restricted to binary classification.

\paragraph{Extracting Positive Paths from the Decision Tree:}
To extract all positive paths from the decision tree, the decision tree is traversed from the root node using a \textit{depth-first search} (DFS) strategy.
At each internal node, the corresponding feature, comparison operator (e.g., $\leq$, $>$), and threshold value were recorded.
Upon reaching a leaf node labeled with a  positive outcome, the complete sequence of conditions along the path, together with its associated confidence score, was stored.
\\\\To prevent the selection of statistically unrepresentative paths, a weighted confidence score was employed.
Let $n_{\text{leaf}}$ denote the number of training samples reaching a given positive leaf, $n_{\text{root}}$ the number of samples at the root node, and $p_{\text{pos}}$ the proportion of positive samples at that leaf.
The confidence score $s$ associated with a positive path is defined as:
\[
    s \;=\; p_{\text{pos}} \cdot \frac{n_{\text{leaf}}}{n_{\text{root}}}.
\]
This definition combines the local confidence of the leaf (via $p_{\text{pos}}$) with its global context (via $n_{\text{leaf}}/n_{\text{root}}$).
This penalizes paths that achieve high purity based on a negligible number of observations, thereby prioritizing paths that are both accurate and statistically significant.
\\\\The Algorithm \ref{alg:get_positive_paths} formally defines the procedure for extracting positive paths from the decision tree.
\begin{algorithm}[H]
    \label{alg:get_positive_paths}
    \caption{Get Positive Paths}
    \begin{algorithmic}[1]
    \Function{GetPositivePaths}{node, current\_path, positive\_paths}
        \If{node \textbf{is} leaf}
            \If{node.label == positive}
                \State Add (current\_path, node.confidence) to positive\_paths
            \EndIf
        \Else
            \State Append (node.feature, $\le$, node.value) to current\_path
            \State Call \textbf{GetPositivePaths}(node.left, current\_path, positive\_paths)
            \State Remove last element from current\_path
            \\
            \State Append (node.feature, $>$, node.value) to current\_path
            \State Call \textbf{GetPositivePaths}(node.right, current\_path, positive\_paths)
            
            \State Remove last element from current\_path
        \EndIf
    \EndFunction
    \end{algorithmic}
\end{algorithm}

\paragraph{Filtering Compliant Paths:}
For each trace prefix predicted as negative, the set of extracted positive paths was filtered to retain only those that are compliant with the observed activities.
A path is defined as compliant if none of its feature conditions are contradicted by the trace prefix, that is, if every condition along the path is either satisfied or refers to a feature that does not yet appear in the prefix.
Among all compliant paths, the one with the highest confidence score was selected.
In case of a tie in confidence, the shortest path was chosen as a secondary selection criterion.

\paragraph{Generating Recommendations:}
Once the most suitable positive compliant path was identified, recommendations were generated by determining which activities 
needed to be added to the current trace in order to satisfy the conditions of that path.
For each test-set prefix, the recommendation set is defined as follows:
\begin{itemize}
    \item \textit{None}, if the trace was already predicted to result in a positive outcome;
    \item the empty set, if no compliant positive path could be identified;
    \item otherwise, the set of activities corresponding to the unsatisfied conditions along the selected positive path.
\end{itemize}

\subsection{Evaluation of Recommendations}
The quality of the generated recommendations was evaluated by comparing them against the complete traces in the test set, which serve as ground truth.
Each trace in the test set was matched with its corresponding prefix and the recommendation generated for that prefix.
\\\\Recommendations for which no action was required were excluded from the evaluation.
Recommendations consisting of an empty set were considered \emph{not followed}, reflecting the absence of a feasible corrective action.
A recommendation was considered \emph{followed} if and only if all Boolean conditions associated with the selected path were satisfied in the full trace.
If any condition was violated, the recommendation was classified as \emph{not followed}.
\\\\The recommendation outcome (followed or not followed) was then compared with the ground truth label of the trace to derive an approximate confusion matrix defined as follows:
\begin{itemize}
    \item \textbf{True Positives}: the recommendation was followed in the actual trace and the ground truth outcome is positive.
    \item \textbf{False Positives}: the recommendation was followed in the actual trace but the ground truth outcome is negative.
    \item \textbf{True Negatives}: the recommendation was not followed in the actual trace and the ground truth outcome is negative.
    \item \textbf{False Negatives}: the recommendation was not followed in the actual trace but the ground truth outcome is positive.
\end{itemize}

Based on this confusion matrix, standard evaluation metrics such as accuracy, precision, recall, and F1-score were computed to assess the effectiveness of the generated recommendations.
